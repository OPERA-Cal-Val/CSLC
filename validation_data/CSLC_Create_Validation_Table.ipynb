{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow to create and maintain the validation table for CSLC Cal/Val\n",
    "\n",
    "This notebook demonstrates how to query the public S3 bucket hosting granules associated with bursts identified for CSLC Cal/Val activities.\n",
    "\n",
    "Specifically the motivation here to access + record the preqrequiste information from each granule in order to virtually perform Cal/Val analyses.\n",
    "\n",
    "For reference, the following resources were used to help create this notebook:\n",
    "https://alexwlchan.net/2017/listing-s3-keys/\n",
    "https://github.com/boto/boto3/issues/1200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prerequisite modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "import fsspec\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import h5py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import shapely.wkt as wkt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static variables that identify S3 paths to data\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Only change IF you know what you are doing (i.e. itentional changes to reflect hypothetical migration of validation data).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set S3 path variables\n",
    "bucket = 'opera-pst-rs-pop1'\n",
    "prefix = 'products/CSLC_S1'\n",
    "suffix = 'Z.h5'\n",
    "s3_path = f's3://{bucket}'\n",
    "DATA_ROOT = 'science/SENTINEL1'\n",
    "#DATA_ROOT = 'data'\n",
    "id_path = f'{DATA_ROOT}/identification'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load function to query S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_s3_keys(bucket, prefix='', suffix='', burstId=''):\n",
    "    \"\"\"\n",
    "    Generate the keys in an S3 bucket.\n",
    "\n",
    "    :param bucket: Name of the S3 bucket.\n",
    "    :param prefix: Only fetch keys that start with this prefix.\n",
    "    :param suffix: Only fetch keys that end with this suffix.\n",
    "    :param burstId: Only fetch keys that match burstId.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    kwargs = {'Bucket': bucket}\n",
    "\n",
    "    # If the prefix is a single string (not a tuple of strings), we can\n",
    "    # do the filtering directly in the S3 API.\n",
    "    if isinstance(prefix, str):\n",
    "        kwargs['Prefix'] = prefix\n",
    "\n",
    "    while True:\n",
    "        # The S3 API response is a large blob of metadata.\n",
    "        # 'Contents' contains information about the listed objects.\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        for obj in resp['Contents']:\n",
    "            key = obj['Key']\n",
    "            if key.startswith(prefix) and key.endswith(suffix) \\\n",
    "                 and burstId in key:\n",
    "                yield key\n",
    "\n",
    "        # The S3 API is paginated, returning up to 1000 keys at a time.\n",
    "        # Pass the continuation token into the next response, until we\n",
    "        # reach the final page (when this field is missing).\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access or initiate validation table containing links to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access dataframe from file, if it exists\n",
    "validation_csv = Path('validation_table.csv')\n",
    "if validation_csv.is_file():\n",
    "    df = pd.read_csv(validation_csv)\n",
    "    validation_bursts_df = gpd.GeoDataFrame(\n",
    "        df.loc[:, [c for c in df.columns if c != \"geometry\"]],\n",
    "        geometry=gpd.GeoSeries.from_wkt(df[\"geometry\"])\n",
    "        )\n",
    "else:\n",
    "    # otherwise, initialize dataframe\n",
    "    validation_bursts_df = gpd.GeoDataFrame()\n",
    "    # add placeholder columns\n",
    "    validation_bursts_df['burst_id'] = None\n",
    "    validation_bursts_df['date'] = None\n",
    "    validation_bursts_df['cslc_url'] = None\n",
    "    validation_bursts_df['cslc_static_url'] = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access premade, static table containing all bursts identified for CSLC Cal/Val activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list of bursts used for validation\n",
    "validation_bursts = Path('validation_bursts.csv')\n",
    "if validation_bursts.is_file():\n",
    "    df = pd.read_csv(validation_bursts)\n",
    "    burstId_list = df['burst_id'].to_list()\n",
    "else:\n",
    "    raise Exception(f'Expected burst record {validation_bursts.absolute()} '\n",
    "                    'not found. Check working directory.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query server and build up validation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying server for burst id t064_135523_iw2\n",
      "Df status             burst_id      date   \n",
      "0    t064_135523_iw2  20141221  \\\n",
      "1    t064_135523_iw2  20150114   \n",
      "2    t064_135523_iw2  20150207   \n",
      "3    t064_135523_iw2  20150327   \n",
      "4    t064_135523_iw2  20150502   \n",
      "..               ...       ...   \n",
      "289  t064_135523_iw2  20211027   \n",
      "290  t064_135523_iw2  20211108   \n",
      "291  t064_135523_iw2  20211120   \n",
      "292  t064_135523_iw2  20211202   \n",
      "293  t064_135523_iw2  20211214   \n",
      "\n",
      "                                              cslc_url   \n",
      "0    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...  \\\n",
      "1    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "2    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "3    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "4    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "..                                                 ...   \n",
      "289  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "290  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "291  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "292  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "293  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "\n",
      "                                       cslc_static_url   \n",
      "0    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...  \\\n",
      "1    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "2    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "3    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "4    s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "..                                                 ...   \n",
      "289  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "290  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "291  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "292  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "293  s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_...   \n",
      "\n",
      "                                              geometry  \n",
      "0    POLYGON ((-118.06338 34.69646, -118.00975 34.7...  \n",
      "1    POLYGON ((-118.06340 34.69691, -118.00976 34.7...  \n",
      "2    POLYGON ((-118.07936 34.69512, -118.02538 34.7...  \n",
      "3    POLYGON ((-118.08244 34.70387, -118.02816 34.7...  \n",
      "4    POLYGON ((-118.08329 34.70454, -118.02918 34.7...  \n",
      "..                                                 ...  \n",
      "289  POLYGON ((-118.08002 34.70643, -118.02532 34.7...  \n",
      "290  POLYGON ((-118.07931 34.70600, -118.02461 34.7...  \n",
      "291  POLYGON ((-118.07900 34.70620, -118.02431 34.7...  \n",
      "292  POLYGON ((-118.07902 34.70631, -118.02432 34.7...  \n",
      "293  POLYGON ((-118.07967 34.70617, -118.02498 34.7...  \n",
      "\n",
      "[294 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# query products on S3 bucket\n",
    "for burstId in burstId_list:\n",
    "    # adjust burst strings to reflect product name convention\n",
    "    query_burstId = burstId.upper().replace('_','-')\n",
    "    print(f'Querying server for burst id {burstId}')\n",
    "    for key in get_matching_s3_keys(bucket=bucket,\n",
    "                                    prefix=prefix,\n",
    "                                    suffix=suffix,\n",
    "                                    burstId=query_burstId):\n",
    "        # only proceed if file not already captured in records\n",
    "        # and only if there is a valid corresponding static layer\n",
    "        cslc_url = f'{s3_path}/{key}'\n",
    "        cslc_static_url = Path(cslc_url)\n",
    "        cslc_static_url = str(Path(str(cslc_static_url.parent) + \\\n",
    "                          '_static_layers/' + \\\n",
    "                          cslc_static_url.name[:-3] + '_static_layers.h5'))\n",
    "        cslc_static_url = cslc_static_url[:3] + '/' + cslc_static_url[3:]\n",
    "\n",
    "        if cslc_url not in validation_bursts_df['cslc_url'].values.astype(str) \\\n",
    "            and '_v0.0_202303' not in cslc_static_url:\n",
    "            # get date\n",
    "            file_path = Path(key)\n",
    "            filename = file_path.name\n",
    "            date = filename.split('_')[-3][:8]\n",
    "\n",
    "            # check if geometry for burst already in df\n",
    "            geom_check = validation_bursts_df['burst_id'] == burstId\n",
    "            idx_geo = next(iter(geom_check.index[geom_check]), False)\n",
    "            if idx_geo != False:\n",
    "                geometry = validation_bursts_df.loc[idx_geo]['geometry']\n",
    "            else:\n",
    "                # otherwise, read file to access geometry\n",
    "                s3f = fsspec.open(cslc_url, mode='rb', anon=True,\n",
    "                                  default_fill_cache=False)\n",
    "                with h5py.File(s3f.open(),'r') as h5:\n",
    "                    geometry = h5[f'{id_path}/'\n",
    "                                  'bounding_polygon'][()].astype(str)\n",
    "                geometry = wkt.loads(geometry)\n",
    "\n",
    "            # create dictionary for this file\n",
    "            file_dict = {'burst_id': burstId,\n",
    "                         'date': date,\n",
    "                         'cslc_url': cslc_url,\n",
    "                         'cslc_static_url': cslc_static_url,\n",
    "                         'geometry': geometry}\n",
    "            # append to records\n",
    "            validation_bursts_df = pd.concat([validation_bursts_df, \\\n",
    "                gpd.GeoDataFrame([file_dict])], ignore_index=True)\n",
    "\n",
    "    print('Df status', validation_bursts_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save validation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by time\n",
    "validation_bursts_df = validation_bursts_df.sort_values(by=['burst_id', 'date'], ascending=[True, True])\n",
    "# save table to file\n",
    "validation_bursts_df.to_csv('validation_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calval_CSLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
